%*******10********20********30********40********50********60********70********80

% For all chapters, use the newdefined chap{} instead of chapter{}
% This will make the text at the top-left of the page be the same as the chapter

\chap{Αξιολόγηση \& Συμπεράσματα}

In this work, we have presented a thorough overview of the theory and applications of augmented reality. We have concentrated on marker-based tracking and lightweight single-camera approaches, but also gave an overview of alternative tracking methods and referred to how additional cameras, sensors and other devices are used in different types of AR applications. We discussed the ways in which basic AR applications can be enhanced and the ways in which interactions between real and virtual objects can be handled. In addition, the appendices give a comprehensive review of theoretical background of methods and algorithms used in augmented reality. We have also presented how the author has contributed to different issues in AR application development. In addition, we have reported practical experiences in AR application development and usability issues. Furthermore, we reported our research results in many areas of augmented reality. In the previous chapter, we discussed AR application development and application areas in which the use of AR is beneficial, and finally we had a glance at future possibilities of AR. In the following, we summarize the main issues of AR application development and design.

In the current work we have presented the design and implementation of an AR interface to interact with virtual content by means of a pinch gesture performed with bare hands, using the Leap Motion Controller -a depth sensing device- to obtain the information of hands, fingers and articulations. Firstly, we have introduced the basic concepts of interaction in AR, gesture recognition and its acceptance for interaction. A review of different approaches was shown, finding scarce implementations with this specific device, most of the research found included computer vision techniques applied with depth cameras that usually expose raw data while the device delivers the information of hand and fingers directly. Afterwards, we defined a set of guidelines to follow based on perceptual issues and recommendations from previous works, a description of the development frameworks and an architecture to integrate the AR and hand tracking technologies, including the definition of an algorithm to recognize pinch gestures through the device. An evaluation was conducted among different users in order to test the performance of the prototype with a simple grab-move-release task designed for this purpose. We found positive results related to the gesture but various issues in the AR perception. The Leap Motion’s technology is very promising in the sense that it has a potential for wide range of applications for gesture interaction, virtual and augmented reality environments and more robust and serious applications as sign language detection or control. Combined with an AR scenario, is potentially useful for virtual modelling and prototyping, collaborative environments or gaming.


\section{Γενικά}
From the results and findings described previously, on the Test No. 1 5.1, there was no significant difference on time between the pinch-release movement task performed with both algorithms, invalidating our first thought, however, after looking at the learnability aspect in the pinchrelease movement within our implementation, which turned out to be non-significant as well, the research focus on other clues that could sustain our hypothesis: The user’s interaction within the virtual space improves easily with the time, chapter 1, leading to verify the additional data collected and measure the time when a hand is recognized and the pinch gesture is performed. The new results showed that our algorithm performed well along the attempts although there were random results in the attempts that does not reflect precisely if it was easier or not, - in general, this behaviour was seen in both cases- concluding that actually there is a decrease on time of each attempt when performing the gesture, validating the learnability aspect in the gesture performance, but not when moving the object to the specified area, in this case, the results were very smooth, meaning that the average time it took to grab-move-release was almost the same in all the samples. Furthermore, when comparing these results within both algorithms we found that there was a relevant improvement with our algorithm, validating our first assumption made, but on different events in the scene. On the qualitative results, the agreement with the learning effect statement is mutual among the users that stated to improve at some level on each attempt while on the SUS, the detection of problems that influenced our results corroborates the dispersion of data we have, specially during the grabbing task -that can be inferred from the time it took- that it was more difficult to initiate the grabbing action than manipulating the object with it. One problem that affected the performance initially was the depth perception of the users, where the point of view of the camera did not help the user to perceive the exact location of the objects in the z-axis(depth) and y-axis(height), even when the farther objects were smaller than the closer ones, it was observed that users struggle with this problem frequently; just after recognizing the environment, users take the tabletop marker as a reference to infer the locations above it, this achievement is important, as it shows the inner relationship between the real and virtual worlds perceived by the users, however, the awareness was not immediate and in this sense, more visual cues should guide the user through the augmentation to offer the perception of depth in a proper way like illumination and shadowing[55] or meshes on the scene[32]. Although the occlusion problem is not considered in this project, little evidence of its awareness should be taken into consideration. During the tests, we could see that there is an immediate and sufficient awareness from the users that a virtual hand is drawn on the top of their real one and it is controlled by their hand movements while other virtual objects react according to it. However, few participants initially tried to grab the objects focusing on their real hand rather than using the virtual, hence identifying the problem of occlusion at the time of trying to grab the objects and decreasing the level of immersion at a first stage. The use of just a real hand would improve the sensation of grabbing the object as in the real world. Lastly, the results of the second test shows the effect of the limits given by the interaction space of the device itself where there is a progressive increase of time to move objects around the center of the scenario, pointing increasing time intervals while moving objects on the boundaries of the interaction space.
\section{Τεχνικά Χαρακτηριστικά}

\section{Παρατηρήσεις}

We have designed and developed a prototype for a Gesture-based AR application, Despite it’s in an early stage, it could be used as basis for future developments in this area. Furthermore, a proposed integration of an architecture for mobile devices was designed and presented as a proof of concept where the data is sent through wireless connection, this will be useful in the near future, as currently development is this area is being carried out 1. To support the development, we have reviewed and analysed the capabilities of the device, based on few works published at the moment and presenting our experimental findings in the field of AR. Additionally, we conducted a usability study SUS to verify the user experience issues related and serve as basis for further improvements.

Σκοπός της παρούσας διπλωματικής εργασίας είναι η ανάπτυξη εφαρμογών επαυξημένης πραγματικότητας βάσει επίπεδου προτύπου, με αξιοποίηση μεθόδων και αλγορίθμων της φωτογραμμετρίας και της όρασης υπολογιστών. Στο πλαίσιο αυτό, έγινε μία περιγραφή της έννοιας της επαυξημένης πραγματικότητας, παρουσιάστηκε το θεωρητικό υπόβαθρο των διαδικασιών οι οποίες χρησιμοποιήθηκαν για την περάτωση των εφαρμογών και έγινε αναφορά στο προγραμματιστικό μέρος των εφαρμογών (περιβάλλον ανάπτυξης, γλώσσα προγραμματισμού και χρησιμοποιούμενες βιβλιοθήκες) ώστε στο τελευταίο κεφάλαιο της εργασίας να παρουσιαστούν τα αποτελέσματα των εφαρμογών και η ακριβής διαδικασία που ακολουθήθηκε. Έχοντας ολοκληρώσει την ανάπτυξη των εφαρμογών, κρίνεται αναγκαία η επισήμανση κάποιων παρατηρήσεων και συμπερασμάτων καθώς επίσης και διαφόρων προτάσεων για μελλοντική ενασχόληση και βελτίωση αυτών. Τα αποτελέσματα των εφαρμογών κρίνονται ικανοποιητικά. Τόσο η εφαρμογή επαυξημένης πραγματικότητας εσωτερικού χώρου όσο και η αντίστοιχη εξωτερικού χώρου αναγνωρίζουν επιτυχώς το πρότυπο επίπεδο αντικείμενο όταν αυτό τοποθετηθεί στο οπτικό πεδίο της κάμερας, ακόμη και στην περίπτωση κατά την οποία απεικονίζεται στη σκηνή ένα τμήμα του. Επίσης, η αναγνώρισή του γίνεται ανεξάρτητα από τις συνθήκες φωτισμού, τον προσανατολισμό του πρότυπου αντικειμένου και το μέγεθός του. Η σωστή αναγνώρισή του – η οποία οφείλεται κυρίως στο χρησιμοποιούμενο αλγόριθμο ανίχνευσης και περιγραφής των σημείων ενδιαφέροντος – σε συνδυασμό με την ορθότητα των αποτελεσμάτων της βαθμονόμησης είναι τα δύο βασικότερα στοιχεία που κρίνουν την επιτυχία επαύξησης του πραγματικού κόσμου και τη ρεαλιστικότητα των επαυξημένων σκηνών. Εξάλλου, η ρεαλιστική επαύξηση της πραγματικότητας, δηλαδή η ενσωμάτωση του εικονικού μοντέλου στον τρισδιάστατο χώρο έτσι ώστε να μην ξεχωρίζει από την πραγματική σκηνή αλλά να αποτελεί ένα με αυτή, είναι ένας από τους σημαντικότερους στόχους των εφαρμογών επαυξημένης πραγματικότητας, ο οποίος επιτεύχθηκε σε υψηλό βαθμό στην παρούσα εργασία. Μη ρεαλιστική είναι η επαύξηση της σκηνής στην περίπτωση που ένα αντικείμενο του πραγματικού κόσμου τοποθετηθεί μπροστά από τη θέση στην οποία προορίζεται να τοποθετηθεί το εικονικό μοντέλο, προς την πλευρά της κάμερας. Η ιδανική λύση θα ήταν η απόκρυψη του τμήματος του τρισδιάστατου μοντέλου επαύξησης που κρύβεται από το πραγματικό αντικείμενο. Ωστόσο, στις εφαρμογές που προγραμματίστηκαν, κάθε στιγμιότυπο της πραγματικής σκηνής ορίζεται ως εικόνα που καλύπτει τη σχεδιαστική επιφάνεια του παραθύρου επαύξησης της πραγματικότητας, αποτελώντας το φόντο του, χωρίς να εξάγεται από αυτό η πληροφορία της τρίτης διάστασης. Η τελευταία θα μπορούσε να χρησιμοποιηθεί στον ορισμό των αποκρύψεων. Συνεπώς, μία ενδιαφέρουσα μελλοντική επέκταση των εφαρμογών είναι η κατασκευή σε πραγματικό χρόνο του χάρτη βάθους (depth map) για κάθε στιγμιότυπο, για τον ορισμό των τμημάτων των εικονικών μοντέλων τα οποία αποκρύπτονται από τα αντικείμενα του πραγματικού κόσμου. Οι εφαρμογές που αναπτύχθηκαν έχουν ικανοποιητικά αποτελέσματα στην περίπτωση που το πρότυπο αντικείμενο είναι επίπεδο ή έχει μικρό ανάγλυφο σε σχέση με την απόσταση λήψης, λόγω της γεωμετρικής σχέσης του δισδιάστατου προβολικού μετασχηματισμού που θεωρήθηκε ότι συνδέει την εικόνα - πρότυπο και το εκάστοτε στιγμιότυπο. Συνεπώς, μία μελλοντική επέκταση των δυνατοτήτων των εφαρμογών θα μπορούσε να είναι η επαύξηση μη επίπεδων σκηνών του πραγματικού κόσμου, ανεξάρτητα από τη γεωμετρία τους. Η λύση σε ένα τέτοιο πρόβλημα μπορεί να προκύψει από την επιπολική γεωμετρία. Η εφαρμογή επαυξημένης πραγματικότητας εσωτερικού χώρου, η οποία υποστηρίζει τη συμπλήρωση της ορθοφωτογραφίας με την πληροφορία της τρίτης διάστασης, ταιριάζει με το μέσο που χρησιμοποιήθηκε για την επαύξηση σε πραγματικό χρόνο, δηλαδή την κάμερα του υπολογιστή, καθώς ο χρήστης μπορεί εύκολα να τοποθετήσει την εκτυπωμένη ορθοφωτογραφία μπροστά από την κάμερα του υπολογιστή του και να εξετάσει το ανάγλυφο της συγκεκριμένης περιοχής. Αντίθετα, δεν θα ήταν διατεθειμένος να μεταφέρει το φορητό υπολογιστή του στον πολυχώρο «Τεχνόπολις» ή στην περιοχή του νέου Μουσείου της Ακρόπολης για να παρακολουθήσει σε ζωντανό χρόνο την επαύξηση της πραγματικότητας στις δύο αυτές τοποθεσίες. Για το λόγο αυτό, η Εφαρμογή 2 δεν προγραμματίστηκε ώστε να είναι πραγματικού χρόνου και προϋποθέτει από το χρήστη να έχει εγγράψει ένα βίντεο μέσω της κινητής συσκευής του και εν συνεχεία να παρακολουθήσει, από το χώρο στον οποίο βρίσκεται ο υπολογιστής του, τις επαυξημένες σκηνές. Ωστόσο, θα ήταν προτιμότερη η επαύξηση της πραγματικότητας σε πραγματικό χρόνο μέσω μίας κινητής συσκευής χειρός. Έτσι, μελλοντικός στόχος είναι η τροποποίηση των εφαρμογών ώστε να εκτελούνται και σε ένα κινητό τηλέφωνο ή σε ένα tablet υπολογιστή, δηλαδή σε συσκευές χειρός που μεταφέρονται εύκολα και μπορούν να χρησιμοποιηθούν χωρίς δυσκολία από χρήστες εφαρμογών επαυξημένης πραγματικότητας. Άλλη πιθανή βελτίωση - διαφοροποίηση των εφαρμογών θα μπορούσε να είναι η εισαγωγή από το χρήστη της εικόνας - πρότυπο και του τρισδιάστατου μοντέλου και ο καθορισμός από αυτόν της επιθυμητής θέσης του τελευταίου σε σχέση με το πρότυπο αντικείμενο. Παράλληλα, η υποστήριξη της δυνατότητας βαθμονόμησης της κάμερας, με την οποία λαμβάνονται τα στιγμιότυπα προς επαύξηση, στην αρχή των εφαρμογών, μέσω λήψης βίντεο μίας σκακιέρας, θα ήταν μία ακόμη χρήσιμη συμπλήρωση των εφαρμογών.Η συμβολή των εφαρμογών επαυξημένης πραγματικότητας και η χρήση τους σε διάφορους τομείς έχει ήδη παρουσιαστεί στο πρώτο κεφάλαιο της παρούσας εργασίας. Όσον αφορά στις συγκεκριμένες εφαρμογές, η Εφαρμογή 1 μπορεί να χρησιμοποιηθεί για την οπτικοποίηση πληροφοριών τρίτης διάστασης και για την εξέταση του αναγλύφου μίας περιοχής με τρόπο παραστατικό, χωρίς να υφίσταται η ανάγκη τρισδιάστατης εκτύπωσης του ΨΜΕ. Μία πιθανή επέκταση της εφαρμογής θα μπορούσε να περιλαμβάνει την εισαγωγή διαφορετικών ΨΜΕ και πρότυπων εικόνων και την αυτόματη αναγνώριση της συγκεκριμένης ορθοφωτογραφίας ή άλλου είδους χάρτη που βρίσκεται στο οπτικό πεδίο της κάμερας, προκειμένου να επαυξηθεί με το κατάλληλο ΨΜΕ. Έτσι, θα μπορούσε να χρησιμοποιηθεί στη χαρτογραφία, καθώς παρέχει ένα ρεαλιστικό και καινοτόμο τρόπο αναπαράστασης της τοπογραφίας μίας περιοχής. Επίσης, θα μπορούσε να δώσει σε μαθητές τη δυνατότητα να εξετάζουν το ανάγλυφο περιοχών που απεικονίζονται στα σχολικά βιβλία γεωγραφίας τους, με τη χρήση της οθόνης ενός υπολογιστή. Επιπλέον, θα μπορούσε να χρησιμοποιηθεί από τουρίστες για την τρισδιάστατη παρατήρηση περιοχών που παρουσιάζουν ιδιαίτερο ενδιαφέρον και απεικονίζονται σε τουριστικούς χάρτες. Η χρησιμότητα της Εφαρμογής 2 θα μπορούσε να συνοψισθεί στην εξέταση αν τα συγκεκριμένα μοντέλα θα μπορούσαν να τοποθετηθούν στις καθορισμένες από την εφαρμογή θέσεις, από αισθητικής άποψης. Ωστόσο, τόσο τα μοντέλα όσο και οι περιοχές που χρησιμοποιήθηκαν είναι ενδεικτικά και περισσότερη σημασία δόθηκε όχι σε αυτά, αλλά στη διαδικασία που ακολουθήθηκε. Έτσι, ανεξάρτητα από τα συγκεκριμένα μοντέλα και τις αντίστοιχες περιοχές, ενδιαφέρουσες χρήσεις της εφαρμογής θα μπορούσαν να είναι η επαύξηση ενός κτηρίου με τμήμα του το οποίο υπήρχε στο παρελθόν αλλά σήμερα έχει καταστραφεί, ή η τοποθέτηση ενός κτηρίου, που δεν έχει ακόμη κατασκευαστεί, στη θέση στην οποία σχεδιάζεται να τοποθετηθεί, για να εξεταστεί αν είναι συμβατό με τον περιβάλλοντα χώρο. Τέλος, λαμβάνοντας υπ΄ όψιν τη μελλοντική επέκταση της εφαρμογής για την υποστήριξη ενός τρισδιάστατου πρότυπου αντικειμένου, ενδιαφέρουσα χρήση της θα μπορούσε να είναι η επαύξηση ενός ημι-κατεστραμμένου αγάλματος ή αρχαίου μνημείου με το τμήμα το οποίο λείπει από τη σημερινή κατάστασή του, για την οπτικοποίηση της μορφής του, όπως ήταν στο παρελθόν.


\section{Περιορισμοί}
During the simulation tests, some limitations and drawbacks emerged, that made us redesign some aspects of our applications. First of all, during blob detection, when the user decides to select and manipulate a virtual chess piece, his hand might be too close to the table, and this has as a result for our program to detect the hand and the table as a single blob, hence the pinch gesture detection fails. These problems are a common thing when using other modern sensors such as the Leap Motion. However, we decided that since, changing the way a blob is detected by the RealSense SDK would be excessive, we could simulate the visual design of a real chessboard which is usually a cube with a speci c height above the tabletop surface. Therefore, in this application, the chessboard is rendered as a grid of multiple cubes with a height of approximately 3,5cm, since this was the minimum value that our program could correctly detect the hand blob. Another problem that has caught our attention during the test simulations, is that due to the wrong detection of a pinch point in 3D space, the user may accidentally move a chess piece in another location than the one he intented to. For example, he may want to move one of his chess pawns 2 squares away from its initial position, but during the translation, the pinch may not be detected and therefore the pawn may move only 1 square away from its initial position. We considered that there may be several solutions for this problem. For instance, instead of the current approach, we could implement a timer effect before a valid move takes place. Then, users would have to pinch for a speci c amount of seconds before a move could be considered as valid. However, we opted not to do this, because we wanted the user to play chess just like in real life and also we could measure and evaluate the wrong and right moves he played during a chess game.

The next limitations were considered for the design, implementation and testing purposes:  As pointed in [40], the Leap Motion’s API stores detected information in a constructed data type that is not modifiable and as there is no easy way to access to a full depth map and potentially correct detected data or make use of the depth map. However, the confidence on the exposed data is enough to work efficiently at the moment.  As seen before, the Vuforia framework is intended to work with mobile devices rather than desktop applications, the see-through concept in AR is fundamental and it cannot be achieved using a desktop screen. However, the integration proposed with mobile devices is difficult at a certain point as the Leap Motion requires a USB connection. It has been managed to send coordinates through a wireless connection but latency issues[54] and the lack of support libraries for mobile platforms requires a higher degree of knowledge to overcome these problems; additionally, the performance in a prototyping stage decreased with this approach. Hence, it has been decided to work in a desktop environment using multi-platform tools, ultimately managing the interaction in a fully controlled environment and without the lack of resources that influence the performance of the application. The details of the proof of concept for mobile devices were explained in the previous chapter 3.7.  The Leap Motion’s limitations at some positions of the hands, the tracking fails when placing the hand perpendicularly to the sensor as the fingers shapes are not in its field of view.  The Test No.2 included a deeper analysis, measuring the position data and time, it would include a description of which hands are used in the right/left regions of the space to observe its performance with outside-in/inside-out movements directed to the space, as sometimes, users tend to perform the pinch-grab gesture from outside the range of the sensor and the easiest solution was to use the left-hand to move content on the right and vice versa. However, due to time constraints, it was not possible.

\section{Αξιολόγηση}
\subsection{Αξιολόγηση SUS}
\subsection{Ερωτηματολόγια}

\section{Συνολική Απόδοση Συστήματος}

