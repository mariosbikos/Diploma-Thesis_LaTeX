%*******10********20********30********40********50********60********70********80

% For all chapters, use the newdefined chap{} instead of chapter{}
% This will make the text at the top-left of the page be the same as the chapter

\chap{Θεωρητικό Υπόβαθρο και Σχετική Βιβλιογραφία} \label{c:complex}
%ΠΕΡΙΓΡΑΦΗ ΤΟΥ ΤΙ ΑΚΡΙΒΩΣ ΠΑΡΟΥΣΙΑΖΕΤΑΙ ΣΤΟ ΚΕΦΑΛΑΙΟ

Στο συγκεκριμένο κεφάλαιο γίνεται επεξήγηση των βασικών εννοιών και τεχνολογιών που αναφέρονται στην εργασία.  the basic concepts and technologies involved in this project: Augmented Reality, the Leap Motion Controller’s technology, the definition of gesture recognition and categorization, targeting a pinch gesture for our purpose. 

Επιπλέον γίνεται ανασκόπηση των σχετικών επιστημονικών εργασιών και εφαρμογών, καθώς και των ανοικτών προκλήσεων στον ερευνητικό τομέα.



\section{Επαυξημένη Πραγματικότητα}
%ΟΡΙΣΜΟΣ+ΤΙ ΥΠΑΡΧΕΙ ΣΗΜΕΡΑ+ΔΙΑΦΟΡΑ ΑΠΟ VR+ OTI EXEI NA KANEI ME AR APO ERGASIES ALLON


%Thomas-cie
Augmented reality is the registration of computer-generated graphical information over a user’s view of the physical world. Supplemental information that is spatially located relative to the user can help to enhance their understanding of the world around them. AR is made up of a combination of virtual and real environments, although the exact make up may vary significantly. Milgram and Kishino used these properties to define a reality-virtuality continuum [Milgram and Kishino 1994], which can be used to compare the various forms of MR by placing them onto a spectrum. At one end of the continuum is the physical world, at the other end are the fully synthetic virtual environments (VR); AR is located somewhere in between, since it is a combination of the two. On the far left of the continuum is the physical world, with no virtual information at all. Moving to the right in the continuum is AR, where artificial objects are added to the physical world. Further to the right in the continuum (but not all the way to the right) is augmented virtuality, where physical world objects (such as a live display of a remote view) are added into a fully immersive virtual environment. On the far right side is a completely synthetic environment, with no information from the physical world being presented. Every type of 3D environment can be placed somewhere along this spectrum, and can be used to easily compare and contrast their properties. Mixed reality is defined as the combination of augmented and augmented virtuality. In his outstanding survey of the discipline, Azuma defines AR systems as those that contain the following three characteristics [Azuma 1997]: (1) it combines the real and virtual; (2) is interactive in real-time; and (3) is registered in 3D. This definition does not limit AR to the use of head-mounted displays (allowing for projectors and handheld displays), but excludes noninteractive media such as movies and television shows. To overlay 3D virtual models onto the user’s view, an AR system requires some form of displayed computer-generated information to be combined with a sensor that can measure the position and orientation of the user’s view. As the user moves through the physical world, the display is updated by the computer in real-time. The accuracy of the virtual objects registered to the physical world influences the realism of the fusion that the user experiences.


%AR=Combination of Computer Graphics & COmputer Vision
Ο συνδυασμός αλγορίθμων και μεθόδων των δύο
αυτών συγγενών επιστημών είναι το κλειδί για την επίτευξη σημαντικών αποτελεσμάτων σε εφαρμογές που επεξεργάζονται εικόνες και εξάγουν πληροφορίες από αυτές


Η επαυξημένη πραγματικότητα, διεθνώς γνωστή ως augmented reality (AR), είναι το επιστημονικό πεδίο που ασχολείται με το συνδυασμό του πραγματικού κόσμου με δεδομένα παραγόμενα από έναν υπολογιστή. Αυτά προσθέτουν επιπλέον πληροφορίες στον πραγματικό κόσμο και βελτιώνουν την αντίληψη που έχει ο άνθρωπος για την πραγματικότητα. Σήμερα γίνονται προσπάθειες για την αξιοποίηση των δυνατοτήτων της πολλά υποσχόμενης εν λόγω τεχνολογίας σε διάφορους τομείς, μέσω της ανάπτυξης εφαρμογών που απευθύνονται σε πληθώρα ανθρώπων, με διαφορετικά ενδιαφέροντα και ασχολίες. 

Οι εφαρμογές επαυξημένης πραγματικότητας που αναπτύχθηκαν είναι εσωτερικού χώρου, η πρώτη, και εξωτερικού χώρου, η δεύτερη, και στηρίζονται στην αναγνώριση ενός επίπεδου αντικειμένου για την επαύξηση της σκηνής. Πρόκειται για εφαρμογές κονσόλας Win32 που εκτελούνται σε ηλεκτρονικούς υπολογιστές με λειτουργικό σύστημα Windows και υποστηρίζουν την επαύξηση της πραγματικότητας με τρισδιάστατα μοντέλα σε πραγματικό χρόνο μέσω της κάμερας του υπολογιστή Η γενική μεθοδολογία που ακολουθήθηκε είναι η είσοδος των στοιχείων του εσωτερικού προσανατολισμού της κάμερας, της εικόνας του πρότυπου επίπεδου αντικειμένου και του τρισδιάστατου μοντέλου, η εξαγωγή χαρακτηριστικών στην εικόνα του επίπεδου αντικειμένου και στο εκάστοτε στιγμιότυπο προς επαύξηση, η ψηφιακή συνταύτιση των εικόνων αυτών, η εξάλειψη των άκυρων ομολογιών, η εύρεση της γεωμετρικής σχέσης που συνδέει τις δύο εικόνες, ο εντοπισμός του επίπεδου αντικειμένου στο στιγμιότυπο και τέλος ο υπολογισμός των στοιχείων του εξωτερικού προσανατολισμού του στιγμιότυπου. Με βάση τα τελευταία, με γνώση της εσωτερικής γεωμετρίας της κάμερας και με θεώρηση της κλίμακας, της θέσης και του προσανατολισμού του τρισδιάστατου μοντέλου επαύξησης εντός του πραγματικού κόσμου, είναι δυνατή η τοποθέτησή του με το σωστό τρόπο και στην κατάλληλη θέση στο παράθυρο θέασης της επαυξημένης σκηνής
%

Η επαυξημένη πραγματικότητα είναι μία επιστημονική περιοχή της έρευνας της Επιστήμης των Υπολογιστών που συνδύαζει τον πραγματικό κόσμο με ψηφιακά δεδομένα. Τείνει να γίνει ένα ευρέως γνωστό και κοινότυπο χαρακτηριστικό  των καταναλωτικών εφαρμογών. Printed books (e.g. Dibitassut) have additional AR content. As a technology, augmented reality is now on the top of the “technology hype curve”. New augmented reality applications mushroom all the time. Even children’s toys increasingly have AR links to digital content. For example, in 2010 Kinder launched chocolate eggs with toys linked to AR content if presented to a webcam. Traditional AR systems, such as systems for augmenting lines and records in sport events on TV, used to be expensive and required special devices. 

This opens mass markets for augmented reality applications as the potential users already have the suitable platform for AR. Furthermore, cloud computing and cloud services enable the use of huge databases even on mobile devices.  



In order for the computer to generate contextual information, it must first understand the user’s context. The parameters of this context are limited to environmental information and the user’s position and orientation within that environment. With such information, the computer can position the augmented information correctly relative to the surrounding environment. This alignment of virtual objects with real scene objects is known as registration. 


The most common definition given by [24] refers to Augmented Reality as an interactive technology that combines real and virtual imagery in real time by registering virtual content onto real world. On a typical AR system, the working process can be divided in two main tasks along the general steps: tracking and registration and it is intended to detect a known pattern stored in memory (marker tracking)[25]. The commonly used technique to perform tracking nowadays is based on optical devices (conventional web camera, ToF, structured light) applying image processing and computer vision algorithms. The simplest tracking method in AR is by using fiducial markers, Figure 1, its basic working process consists on a tracking algorithm that performs a series of image processing tasks over each frame of a video sequence in order to detect where a marker is, and a registration which correlates a virtual object to the physical marker[25]. It consists on threshold the image and look for the edges using a scanline search. With the known edges of the marker, it fits a rectangle by finding the corners based on the maximum diagonals between the points in the edges, this is done with the purpose of delimit the rectangle where a pattern is recognized and matched against a pattern stored in memory. Once we recognize the pattern, the pose of the marker is estimated by calculating the rotation and translation parameters relative to the camera. This action is done using a transformation matrix formed with the angles (rotation) and translation vectors (translation). In other words, we want to know the coordinates of the marker with respect of the camera coordinates using this transformation points called extrinsic parameters (varies according of the movement of the camera) while the intrinsic parameters are used to move from the camera coordinates to the image coordinates and are fixed on the camera by calibration; these are the focal distance, scale parameters and (x,y) center coordinates of the projection image. With the position of the marker detected, a virtual model is placed on the same position of the image coordinate relatively to the marker. This gives the impression that the virtual object is stick to the marker and the process is called registration. The resulting image is shown in a display in which the user see the virtual object superposed over the real world. The process is done dynamically and fast enough to give the impression of real-virtual world correlation. It is not computationally expensive but the marker must be easily recognizable, i.e. the lighting conditions must be favourable and it should not be partially occluded, otherwise the recognition can fail.



Augmented reality (AR) combines real world and digital data. At present, most AR research uses live video images, which the system processes digitally to add computer-generated graphics. In other words, the system augments the image with digital data. Encyclopaedia Britannica [20] gives the following definition for AR: “Augmented reality, in computer programming, a process of combining or ‘augmenting’ video or photographic displays by overlaying the images with useful computer-generated data.” Augmented reality research combines the fields of computer vision and computer graphics. The research on computer vision as it applies to AR includes among others marker and feature detection and tracking, motion detection and tracking, image analysis, gesture recognition and the construction of controlled environments containing a number of different sensors. Computer graphics as it relates to AR includes for example photorealistic rendering and interactive animations. Researchers commonly define augmented reality as a real-time system. However, we also consider augmented still images to be augmented reality as long as the system does the augmentation in 3D and there is some kind of interaction involved.

%AR-VR
The performance requirements of an AR system can be contrasted to a Virtual Reality (VR) system. A virtual reality system is one where the user is immersed in a scene that is completely synthetic, yet perceived to be real. To create a realistic, virtual scene, the detail level of the generated objects must be high and the rendering must be performed in real-time. This level of detail generates a performance hit to the system in order to render such objects. The virtual objects in an AR system however, are not required to be at any particular detail level. The realistic quality of the virtual objects in an AR system is constrained only by the application. The other, and most significant rendering difference between the two types of systems, is the percentage of scene content that is rendered. An AR system that renders only a few simple virtual objects in a scene will require far less rendering power than that of a VR system rendering the entire scene.


The real-time requirement of VR is not a strict requirement of AR. The merging of the real scene with virtual objects can be done in real-time (online), or it can be done at a later time (offline). Depending on the AR application, each could be acceptable. Augmenting a recorded football game with virtual yard line markers can be done in realtime while viewers watch the live game on television. If the same game is not to be viewed live, then the augmentation could be done after the game and displayed whenever the broadcast occurs. In general, the application requirements are flexible in an AR system, whereas the performance requirements of a VR are the same for all VR systems. A second notable contrast between the two systems is the problem of registration. Since registration deals with the merging of real and synthetic objects, VR systems are not concerned with registration. The positions of all objects in a VR scene are described in terms of a common coordinate system. This means that the VR system has the correct registration for free. In terms of performance, the lower rendering cost of AR is counterbalanced by the cost of registration.

The other aspect of the system that works in conjunction with the rendering component is the equipment used to track the user and display the scene. In the VR system, devices are used to track the user along with a display showing the rendered scene. In the AR system, there are several different combinations of equipment used to track and inform the user.


\subsection{Ιστορική Αναδρομή}
%ΣΥΝΤΟΜΗ ΙΣΤΟΡΙΚΗ ΑΝΑΔΡΟΜΗ ΑΠΟ ΑΛΛΕΣ ΕΡΓΑΣΙΕΣ

%krevelen

The first AR prototypes (Fig. 3), created by computer
graphics pioneer Ivan Sutherland and his students at Harvard
University and the University of Utah, appeared in the 1960s
and used a see-through to present 3D graphics [151].
A small group of researchers at U.S. Air Force‟s Armstrong
Laboratory, the NASA Ames Research Center, the
Massachusetts Institute of Technology, and the University of
North Carolina at Chapel Hill continued research during the
1970s and 1980s. During this time mobile devices like the
Sony Walkman (1979), digital watches and personal digital
organisers were introduced. This paved the way for wearable
computing [103, 147] in the 1990s as personal computers
became small enough to be worn at all times. Early palmtop
computers include the Psion I (1984), the Apple Newton
MessagePad (1993), and the Palm Pilot (1996). Today, many mobile platforms exist that may support AR, such as personal
digital assistants (PDAs), tablet PCs, and mobile phones.
It took until the early 1990s before the term „augmented
reality‟ was coined by Caudell and Mizell [42], scientists at
Boeing Corporation who were developing an experimental
AR system to help workers put together wiring harnesses.
True mobile AR was still out of reach, but a few years later
[102] developed a GPS-based outdoor system that presents
navigational assistance to the visually impaired with spatial
audio overlays. Soon computing and tracking devices became
sufficiently powerful and small enough to support
graphical overlay in mobile settings. Feiner et al. [55] created
an early prototype of a mobile AR system (MARS) that
registers 3D graphical tour guide information with buildings
and artefacts the visitor sees. By the late 1990s, as AR became a distinct field of research,
several conferences on AR began, including the International
Workshop and Symposium on Augmented Reality,
the International Symposium on Mixed Reality, and the
Designing Augmented Reality Environments workshop.
Organisations were formed such as the Mixed Reality Systems
Laboratory2 (MRLab) in Nottingham and the Arvika
consortium3 in Germany. Also, it became possible to rapidly
build AR applications thanks to freely available software
toolkits like the ARToolKit. In the meantime, several surveys
appeared that give an overview on AR advances, describe its
problems, classify and summarise developments [17, 19, 28].
By 2001, MRLab finished their pilot research, and the
symposia were united in the International Symposium on
Mixed and Augmented Reality4 (ISMAR), which has become
the major symposium for industry and research to exchange
problems and solutions.For anyone who is interested and wants to get acquainted
with the field, this survey provides an overview of important
technologies, applications and limitations of AR systems.
After describing technologies that enable an augmented reality
experience in Section 2, we review some of the possibilities
of AR systems in Section 3. In Section 4 we discuss a
number of common technological challenges and limitations
regarding human factors. Finally, we conclude with a number
of directions that the authors envision AR research might
take


%-----
Tom Caudell, a researcher at aircraft manufacturer Boeing coined the term augmented reality in 1992. He applied the term to a head-mounted digital display that guided workers in assembling large bundles of electrical wires for aircrafts [21]. This early definition of augmented reality was a system where virtual elements were blended into the real world to enhance the user’s perception. Figure 1 presents Caudell’s head-mounted augmented reality system. Later in 1994, Paul Milgram presented the reality-virtuality continuum [22], also called the mixed reality continuum. One end of the continuum contains the real environment, reality, and the other end features the virtual environment, virtuality. Everything in between is mixed reality (Figure 2). A Mixed Reality (MR) system merges the real world and virtual worlds to produce a new environment where physical and digital objects co-exist and interact. Reality here means the physical environment, in this context often the visible environment, as seen directly or through a video display.In 1997, Ronald Azuma published a comprehensive survey on augmented reality [23] and due to the rapid development in the area produced a new survey in 2001 [24]. He defines augmented reality as a system identified by three characteristics: 􀁸 it combines the real and the virtual 􀁸 it is interactive in real time 􀁸 it is registered in 3D. Milgram and Azuma defined the taxonomy for adding content to reality or virtuality. However, a system can alter the environment in other ways as well; it can, for example, change content and remove or hide objects. In 2002, Mann [25] added a second axis to Milgram’s virtuality-reality continuum to cover other forms of alteration as well. This two-dimensional realityvirtuality- mediality continuum defines mediated reality and mediated virtuality (see left illustration in Figure 3). another. A system can change reality in different ways. It may add something (augmented reality), remove something (diminished reality) or alter it in some other way (modulated reality). Mann also presented the relationships of these areas in the Venn diagram (see right illustration in Figure 3). In diminished reality, we remove existing real components from the environment. Thus, diminished reality is in a way the opposite of augmented reality. Today most definitions of augmented reality and mixed reality are based on the definitions presented by Milgram, Azuma and Mann. However, the categorisation is imprecise and demarcation between different areas is often difficult or volatile, and sometimes even contradictory. For example, Mann defined virtual reality as a sub area of mixed reality, whereas Azuma completely separates total virtuality from mixed reality. We define virtual reality (VR) as an immersive environment simulated by a computer. The simplest form of virtual reality is a 3D image that the user can explore interactively from a personal computer, usually by manipulating keys or the mouse. Sophisticated VR systems consist of wrap-around display screens, actual VR rooms, wearable computers, haptic devices, joysticks, etc. We can expand virtual reality to augmented virtuality, for instance, by adding real elements such as live video feeds to the virtual world. Augmented reality applications mostly concentrate on visual augmented reality and to some extent on tactile sensations in the form of haptic feedback. This work also focuses on visual AR; other senses are covered briefly in Sections 2.5 Multisensory augmented reality and 8.4 Future of augmented reality.



\subsection{Εφαρμογές}
%ΑΝΑΦΕΡΕ ΧΑΡΑΚΤΗΡΙΣΤΙΚΕΣ ΕΦΑΡΜΟΓΕΣ ΣΕ GAMING,IATRIΚΗ, MILITARY,TOURISM

Στην ενότητα αυτή καταγράφονται οι κυριότεροι τομείς στους οποίους η επαυξημένη πραγματικότητα έχει εφαρμογή και αναφέρονται συνοπτικά διάφορα αντιπροσωπευτικά είδη εφαρμογών σε κάθε τομέα. Οι εφαρμογές αυτές μπορούν να χαρακτηριστούν ως εσωτερικού ή εξωτερικού χώρου. Επίσης, μπορούν να διακριθούν σε αυτές που δίνουν στο χρήστη ελευθερία κίνησης και σε εκείνες που προϋποθέτουν ότι αυτός παραμένει στην ίδια θέση. Ακόμη, μπορούν να διακριθούν σε εφαρμογές που δίνουν στο χρήστη μία επαυξημένη αντίληψη της πραγματικότητας και σε εκείνες που δημιουργούν ένα φανταστικό περιβάλλον. Σύμφωνα με την τελευταία αυτή διάκριση [4], οι πρώτες προσθέτουν πληροφορίες που του επιτρέπουν να έχει μία καλύτερη κατανόηση του περιβάλλοντος στο οποίο βρίσκεται, ενώ εκείνες που δημιουργούν ένα φανταστικό περιβάλλον του επιτρέπουν να δει πράγματα που δεν υπάρχουν στον πραγματικό κόσμο. Συναφής με τη διάκριση αυτή είναι και μία άλλη κατηγοριοποίηση των εφαρμογών [41], σύμφωνα με την οποία αυτές χωρίζονται σε εφαρμογές που υπερθέτουν πληροφορίες που δεν αποτελούν μέρος του φυσικού κόσμου, σε αυτές που απεικονίζουν επιπρόσθετες πληροφορίες με τέτοιο τρόπο ώστε να μην ξεχωρίζουν από το πραγματικό περιβάλλον και σε αυτές που απεικονίζουν πληροφορίες που βρίσκονται στο φυσικό περιβάλλον αλλά δεν είναι άμεσα παρατηρήσιμες.

Augmented reality technology is beneficial in several application areas. It is well suited for on-site visualisation both indoors and outdoors, for visual guidance in assembly, maintenance and training. Augmented reality enables interactive games and new forms of advertising. Several location-based services use augmented reality browsers. In printed media, augmented reality connects 3D graphics and videos with printed publications. In addition, augmented reality has been tested in medical applications and for multi-sensory purposes. The following presents a few examples of how visual AR has been used, and multi-sensory AR will be discussed later in Section 2.5. In interior design, augmented reality enables users to virtually test how a piece of furniture fits in their own living room. Augmented reality interior design applications often use still images. However, the user interactions happen in real-time and the augmentation is in 3D. For example in our AR interior application [12], the user takes images of the room and uploads them onto a computer (see Figure 8). The user can then add furniture, and move and rotate it interactively. A more recent example of augmented reality interior design is VividPlatform AR+ [32]. Vivid Works presented it at the 2010 Stockholm Furniture Fair. VividPlatform AR+ also uses still images. Our experience is that users find still images convenient for interior design. However, interior design can use live video in PC environments or on mobile phones as well [33]. Outdoor visualisation systems normally use live video. Figure 9 shows an example of real-time augmented reality outdoor visualisation [34]. Building projects can also be visualised using an augmented reality web camera. The augmented reality web camera can have several user interactions. Using a PTZ camera, the user can pan, tilt and zoom in on the view as in [9], for example. If the system has connection to the BIM (Building Information Model), the user can interact with materials and browse through the timeline of a construction project as we demonstrated in [1]. In assembly, augmented reality applications can show the instructions for the assembler at each stage. The system can display the instructions on a headmounted display as e.g. in our assembly demonstration [2], on a mobile phone [35] or on a normal display (see Figure 10). The user can interact with an assembly system using voice commands, gestures or a keypad as we demonstrated in [7] and [6]. The benefits of augmented reality instructions compared to a printed manual are clear. The user can see instructions from all viewpoints and concentrate on assembly without having to scan through the paper manual.An AR system can aid maintenance work with augmented information, similarly to assembly. For instance, a mobile augmented reality system can provide maintenance workers relevant information from a database [37]. A mobile device is a good choice for displaying information in many cases. However, if the maintenance task is more of a hands-on assembly type of task, a head-mounted display is often a better choice. ARMAR is an augmented reality system for maintenance and repair developed at Columbia University [38, 39]. It uses a head-mounted display to show AR instructions for the maintenance worker, see Figure 11. The qualitative survey with ARMAR showed that the mechanics found the augmented reality condition intuitive and satisfying for the tested sequence of tasks [40].Besides assembly and engine maintenance, augmented reality is also used for teaching maintenance and repair, and for training purposes in several other fields as well. In the game industry, AR has had a breakthrough. AR enables interaction with the user and the environment. Augmented reality can make games more attractive. For example, mobile game developer int13 [41] believes that “Augmented Reality is a promising idea to enhance the player's gaming experience in providing exciting new ways to control his actions, through position and 3D moves.” In addition, accuracy is less critical in games than in industrial or medical applications. Figure 12 is an example of a Kinder augmented reality game. A toy car found in a Kinder Surprise egg will launch an interactive game on a computer. The game detects the object (in this case the toy car) and then uses gesture detection. The user controls the race with hand gestures imitating steering wheel movements. Augmented reality mobile games are very popular; in November 2011, a quick search in the App Store resulted in about 200 mobile AR applications for the iPhone. Figure 13 shows one example of a mobile AR game, AR Defender (by int13, 2010), which works on iPhone and Samsung platforms, for example. It uses markers for camera registration, an example of which is shown in the lower right-hand corner of the left image in Figure 13.SpecTrek (Games4All, 2011) is another augmented reality game for Android phones. It uses GPS and a camera to guide the user to capture ghosts from the environment. In the map view, it shows the locations of the ghosts. In the camera view, it augments the ghosts in the view and allows the user to catch them (Figure 14).


Besides games, location-based augmented reality services are popular on mobile platforms. One example is Wikitude World Browser, which uses GPS, a compass and the camera of the mobile device to augment location-based information for the user. It functions on several platforms (Symbian, Android and iPhone). Wikitude Drive also uses Navteq’s maps to create augmented navigation instructions. Figure 15 shows examples of Wikitude World Browser. Currently several AR mobile browsers are on the market: Layar, Junaio Glue, Acrossair Browser, Yelp monocle, Robot Vision’s Bing Local Search, PresseLite applications, etc. AR browsers have two main approaches. The first approach is to have one browser and then different information environments, and the user can then choose which information the application augments. Layar, Junaio Glue and Wikitude use this approach. (In Junaio, the environments are called “channels”, in Wikitude “worlds” and in Layar “layers”). The user can choose to see tourist information, for example. The other approach is to assign each information layer to a separate application. PresseLite uses this approach; Paris metro Guide and London Cycle Hire for the Tube are separate programs. Yelp is a system used for sharing user reviews and recommendations on restaurants, shopping, nightlife, services, etc. Its Monocle add-on functionality bridges this social media with real world environments using augmented reality. It is probably the world’s first social media browser. The user interface has motion detection; the user activates the monocle by shaking the phone.

Augmented reality by its nature is well suited to advertising. In 2010, different
companies launched advertising campaigns using AR. One of these is Benetton’s
campaign (2010) IT’S:MY:TIME. It connects their advertisements in journals, on
billboards and in product catalogues with augmented reality. They use the same
symbology in all of them (Figure 16). The small icons indicate that the user can
use a webcam or download an application from the App Store. The AR application
then augments videos on top of the marker, e.g. in the catalogue. The PC version
uses Adobe Flash Player, which most users already have installed on the computer
and thus do not need to download anything new.

Augmented reality technology is used to enrich printed media. Esquire magazine published an augmented reality issue in December 2009, Süddeutche Zeitung released their first issue with AR content in August 2010 (Figure 17). In Esquire’s case, users were able to see AR content when they showed the magazine to a PC webcam. In the case of Süddeutche Zeitung, users could see the content with a mobile phone after downloading the application. In Finland, Katso and TVSeiska magazines used AR in cooperation with VTT in advertising a new animated children series called Dibitassut in April 2010. Brazilian newspaper O estado de Sao Paulo has featured regular AR content since 2009.

The idea of an augmented reality book, “the magic book” is at least ten years old [42]. However, it took a while before the technology was robust enough for mass markets. Aliens \& UFOs [43] was probably the first published book with AR content. In 2010, publishers released several AR books, e.g. Dinosaurs Alive\! [44], Fairyland Magic [45], Dibitassut [46] and [47], and the trend continues. Dibitassut (“Dibidogs” in English) has a program made by VTT, which users can download and install on their own computers. Users can see augmented animations using a webcam (see Figure 18).



%AR for entertainment and gaming

Η επαυξημένη πραγματικότητα έχει διεισδύσει στον τομέα της ψυχαγωγίας, δείχνοντας τις συναρπαστικές δυνατότητές της. Κυκλοφορούν πολλά παιχνίδια επαυξημένης πραγματικότητας, τα οποία προσελκύουν το κοινό λόγω της δυνατότητας που του προσφέρουν να αλληλεπιδρά σε πραγματικό χρόνο τόσο με πραγματικά όσο και με εικονικά αντικείμενα. Μπορεί να απευθύνονται σε έναν ή περισσότερους χρήστες και να χρησιμοποιούν κινητά τηλέφωνα, υπολογιστές, φορητούς ή μη, ή ΗΜDs, προσφέροντας μοναδικές εμπειρίες στους χρήστες. Πέρα όμως από τα παιχνίδια, υπάρχουν και λογοτεχνικά βιβλία επαυξημένης πραγματικότητας για παιδιά αλλά και κόμικς [47], όπου τρισδιάστατες σκηνές της ιστορίας παρουσιάζονται πάνω από τις πραγματικές σελίδες και καθιστούν πιο ενδιαφέρουσα την εμπειρία του διαβάσματος. Κοινή είναι πλέον η χρήση της στα καθημερινά δελτία καιρού. Ο τηλεθεατής. μέσω του δέκτη του, βλέπει τον παρουσιαστή μπροστά από το χάρτη πρόγνωσης του καιρού, ο οποίος στην πραγματικότητα δεν υπάρχει. Με χρήση της επαυξημένης πραγματικότητας, το φόντο μπροστά από το οποίο βρίσκεται ο παρουσιαστής, αντικαθίσταται σε πραγματικό χρόνο από το χάρτη, ο οποίος μάλιστα περιλαμβάνει κινούμενα γραφικά στοιχεία. Η επαυξημένη πραγματικότητα χρησιμοποιείται και στον αθλητισμό και η τεχνολογία αυτή εφαρμόζεται ήδη κατά την αναμετάδοση αγώνων. Ένα παράδειγμα αποτελεί η παραγόμενη από υπολογιστή κίτρινη γραμμή που φαίνεται στα γήπεδα των ποδοσφαιρικών αγώνων στους τηλεοπτικούς δέκτες (βλ. Εικόνα 1-15) και είναι ορατή μόνο από τους τηλεθεατές, διευκολύνοντάς τους στην κατανόηση τυχούσας παράβασης των κανονισμών του παιχνιδιού [1], [48]. Επίσης, η επαυξημένη πραγματικότητα χρησιμοποιείται σε πληθώρα αθλητικών γεγονότων για να δείξει διαφημίσεις να υπερτίθενται σε συγκεκριμένες περιοχές της μεταδιδόμενης εικόνας [1], [7].
%krevelen
Like VR, AR can be applied in the entertainment industry to
create AR games, but also to increase visibility of important
game aspects in life sports broadcasting. In these cases where
a large public is reached, AR can also serve advertisers to
show virtual ads and product placements.

-Sports broadcasting
Swimming pools, football fields, race tracks and other
sports environments are well-known and easily prepared,
which video see-through augmentation through tracked
camera feeds easy. One example is the Fox-Trax system [43],
used to highlight the location of a hard-to-see hockey puck as
it moves rapidly across the ice, but AR is also applied to
annotate racing cars (Fig. 21a), snooker ball trajectories, life
swimmer performances, etc. Thanks to predictable environments
(uniformed players on a green, white, and brown field) and chroma-keying techniques, the annotations are
shown on the field and not on the players (Fig. 21b).

-Games
Extending on a platform for military simulation [128]
based on the ARToolKit, Piekarski and Thomas [127] created
„ARQuake‟ where mobile users fight virtual enemies in a
real environment. A general purpose outdoor AR platform,
„Tinmith-Metro‟ evolved from this work and is available at
the Wearable Computer Lab37 [126], as well as a similar
platform for outdoor games such as „Sky Invaders‟ and the
adventurous „Game-City‟ [45]. Crabtree et al. [50] discuss
experiences with mobile MR game „Bystander‟ where virtual
online players avoid capture from real-world cooperating
runners.
A number of games have been developed for prepared
indoor environments, such as the alien-battling „Aqua-
Gauntlet‟ [155], dolphin-juggling „ContactWater‟, „ARHockey‟,
and „2001 AR Odyssey‟ [154]. In „AR-Bowling‟
Matysczok et al. [104] study game-play, and Henrysson et al.
[71] created AR tennis for the Nokia mobile phone (Fig. 22).
Early AR games also include AR air hockey [116], collaborative
combat against virtual enemies [117], and an
AR-enhanced pool game [78].




%Medical apps



Similar to maintenance personnel, roaming nurses and
doctors could benefit from important information being
delivered directly to their glasses [68]. Surgeons however
require very precise registration while AR system mobility is
less of an issue. An early optical see-through augmentation is
presented by Fuchs et al. [62] for laparoscopic surgery36
where the overlaid view of the laparoscopes inserted through
small incisions is simulated (Fig. 19). Pietrzak et al. [129] confirm that the use of 3D imagery in laparoscopic surgery
still has to be proven, but the opportunities are well documented There are many AR approaches being tested in medicine
with live overlays of ultrasound, CT, and MR scans. Navab et
al. [114] already took advantage of the physical constraints of
a C-arm x-ray machine to automatically calibrate the cameras
with the machine and register the x-ray imagery with the real
objects. Vogt et al. [160] use video see-through HMD to
overlay MR scans on heads and provide views of tool manipulation
hidden beneath tissue and surfaces, while Merten
[106] gives an impression of MR scans overlaid on feet (Fig.
20). Kotranza and Lok [92] observed that augmented patient
dummies with haptic feedback invoked the same behaviour
by specialists as with real patients.

Ένα από τα πιο σημαντικά πεδία εφαρμογών επαυξημένης πραγματικότητας είναι εκείνο που σχετίζεται με τον τομέα της ιατρικής. Η τεχνολογία αυτή μπορεί να χρησιμοποιηθεί στη διάγνωση, στη θεραπεία μίας νόσου και στην εκτέλεση μίας χειρουργικής επέμβασης. Όσον αφορά στη διάγνωση, δεδομένα που συλλέγονται, για παράδειγμα, από μαγνητική τομογραφία, αξονική τομογραφία ή απεικονίσεις υπερήχων μπορούν να συνδυαστούν έτσι ώστε να υπερτεθούν σε πραγματικό χρόνο σε έναν πραγματικό ασθενή συγκεκριμένες ανατομικές πληροφορίες. Το γεγονός αυτό δίνει στο γιατρό τη δυνατότητα να δει στο εσωτερικό του ασθενούς κατά την ώρα της εξέτασης και συμβάλλει στην ολοκλήρωση της διάγνωσης με ένα τρόπο περισσότερο καινοτόμο σε σχέση με την απλή εξέταση ξεχωριστών εικονικών δεδομένων (βλ. Εικόνα 1-11) [1], [4], [42], [43]. Ακόμη, τέτοιου είδους πληροφορίες είναι πολύ σημαντικές στον τομέα της ελάχιστα επεμβατικής χειρουργικής, διότι
παρέχουν μία εικόνα του εσωτερικού του ασθενούς, χωρίς την ανάγκη για μεγαλύτερες τομές
[5].Κατά τη διάρκεια μίας επέμβασης, η επαυξημένη πραγματικότητα θα μπορούσε να χρησιμοποιηθεί για την αναγνώριση και επισήμανση οργάνων του ασθενούς και μελών του σώματός του στα οποία θα πρέπει – ή θα απαγορεύεται – να επέμβουν οι γιατροί. Επίσης, ο γιατρός μπορεί να παρατηρεί την κοιλιά της εγκύου και να βλέπει την τρισδιάστατη αναπαράσταση του εμβρύου. Μία τέτοια προσπάθεια έγινε στο Πανεπιστήμιο της Νότιας Καρολίνας στο Chapel Hill από μία ερευνητική ομάδα, η οποία διεξήγαγε δοκιμαστικές σαρώσεις της μήτρας εγκύου με αισθητήρα υπερήχων, δημιουργώντας μία τρισδιάστατη αναπαράσταση του εμβρύου και εμφανίζοντάς τη σε μία συσκευή HMD [4], [5]. Παράλληλα, εικονικές οδηγίες θα μπορούσαν να υπενθυμίζουν στο χειρούργο τα βήματα μίας εγχείρισης.

%combat and simulation

Η επαυξημένη πραγματικότητα εδώ και πολλά χρόνια έχει στρατιωτικές εφαρμογές. Τα Head-Up Displays (HUDs) και τα Helmet-Mounted Displays (HMDs) στα μαχητικά αεροσκάφη παρέχουν στους πιλότους οπτικές ενδείξεις για τους στόχους, τις απειλές και άλλες πληροφορίες – όπως την ταχύτητα ή το υψόμετρο – ενσωματωμένες στον πραγματικό κόσμο. Όπως υπονοεί και το όνομά τους, τα πρώτα αποτελούν μία διάφανη συσκευή που τοποθετείται στο οπτικό πεδίο των πιλότων και δείχνει τις επιπρόσθετες πληροφορίες, επιτρέποντάς τους να έχουν «το κεφάλι ψηλά» (βλ. Εικόνα 1-14), ενώ τα HMDs προσαρμόζονται στο κράνος τους και προβάλλουν πληροφορίες μπροστά στα μάτια τους. Έτσι, αυτοί δεν αναγκάζονται να στρέψουν το βλέμμα τους για να δουν τις πληροφορίες που χρειάζονται σε άλλα όργανα, αποφεύγοντας έτσι τον κίνδυνο απόσπασης της προσοχής τους και συνακόλουθου ενδεχόμενου λανθασμένου χειρισμού [44], [45], [46]. Επίσης, σε περίπτωση μάχης, ένα σύστημα επαυξημένης πραγματικότητας θα μπορούσε να προβάλλει χρήσιμα δεδομένα σε ειδικά γυαλιά των στρατιωτών σε πραγματικό χρόνο. Για παράδειγμα, άνθρωποι ή διάφορα αντικείμενα θα μπορούσαν να επισημαίνονται με κατάλληλα σήματα, τα οποία να δείχνουν αν πρόκειται για πιθανούς εχθρούς ή κινδύνους [1]. Τα τελευταία χρόνια, μάλιστα, έχοντας καταστεί κατανοητή η μεγάλη συμβολή της επαυξημένης πραγματικότητας σε στρατιωτικές εφαρμογές, ερευνητικά προγράμματα έχουν χρηματοδοτηθεί από την υπηρεσία DARPA (Defense Advanced Research Projects Agency) του Υπουργείου Άμυνας των Ηνωμένων Πολιτειών, το ερευνητικό εργαστήριο του Στρατού των Ηνωμένων Πολιτειών ARL (Army Research Laboratory) και το Γραφείο Ναυτικών Ερευνών των Ηνωμένων Πολιτειών ONR (Office of Naval Research) για την ανάπτυξη της τεχνολογίας αυτής. Ο στόχος των παραπάνω προγραμμάτων είναι η αύξηση της επίγνωσης της κατάστασης από την πλευρά των στρατιωτών και των διοικητών, τόσο στην ύπαιθρο όσο και κάτω από το νερό, μέσω της τεχνολογίας της επαυξημένης πραγματικότητας [44].
%krevelen
Satellite navigation, heads-up displays for pilots, and also
much of the current AR research at universities and corporations
are the result of military funding. Companies like
Information in Place have contracts with the Army, Air Force
and Coast Guard, as land warrior and civilian use of AR may
overlap in for instance navigational support, communications
enhancement, repair and maintenance and emergency medicine.
Extra benefits specific for military users may be training
in large-scale combat scenarios and simulating real-time
enemy action, as in the Battlefield Augmented Reality System
(BARS) by Julier et al. [81] and research by Piekarski et
al. [128]. Not overloading the user with too much information
is critical and is being studied by Julier et al. [82]. The
BARS system also provides tools to author the environment
with new 3D information that other system users see in turn
[22]. Azuma et al. [20] investigate the projection of reconnaissance
data from unmanned air vehicles for land warriors.

%assembly
Since BMW experimented with AR to improve welding
processes on their cars [141], Pentenrieder et al. [124] shows
how Volkswagen use AR in construction to analyse interfering
edges, plan production lines and workshops, compare
variance and verify parts. Assisting the production process at
Boeing, Mizell [109] use AR to overlay schematic diagrams
and accompanying documentation directly onto wooden
boards on which electrical wires are routed, bundled, and
sleeved. Curtis et al. [51] verify the AR and find that workers
using AR create wire bundles as well as conventional approaches,
even though tracking and display technologies
were limited at the time.
At EADS, supporting EuroFighter‟s nose gear assembly is
researched [61] while [163] research AR support for Airbus‟
cable and water systems (Fig. 18). Leading (and talking)
workers through the assembly process of large aircraft is not
suited for stationary AR solutions, yet mobility and tracking
with so much metal around also prove to be challenging.
An extra benefit of augmented assembly and construction
is the possibility to monitor and schedule individual progress
in order to manage large complex construction projects. An
example by Feiner et al. [56] generates overview renderings
of the entire construction scene while workers use their HMD
to see which strut is to be placed where in a space-framestructure. Distributed interaction on construction is further
studied by Olwal and Feiner [120].
\subsection{Μέθοδοι Επαύξησης}



\section{Pinhole Camera Model}
%TO ΜΟΝΤΕΛΟ ΚΑΜΕΡΑΣ ΑΠΟ ΑΛΛΗ ΕΡΓΑΣΙΑ-

\section{Βαθμονόμηση}
%Η ΔΙΑΔΙΚΑΣΙΑ ΒΑΘΜΟΝΟΜΗΣΗΣ ΚΑΙ ΓΕΝΙΚΑ Η ΘΕΩΡΙΑ ΑΠΟ ΠΙΣΩ(ΤΟ ΠΩς ΓΙΝΕΤΑΙ ΣΤΟ ΚΕΦΑΛΑΙΟ 4)

\subsection{Intrinsics}
\subsection{Extrinsics}




\section{Tracking}
%ΓΕΝΙΚΑ ΑΝΑΦΕΡΕ ΤΙ ΕΙΝΑΙ ΤΟ TRACKING
\subsection{Marker Tracking}
%MONO FIDUCIAL MARKER TRACKING
    
\subsection{Markerless Tracking}
%SLAM-PTAM,FEATURE DETECTION,SURF ETC




\section{Αναγνώριση Χειρονομιών}
%ΓΕΝΙΚΑ ΓΙΑ ΤΗΝ ΑΝΑΓΝΩΡΙΣΗ ΧΕΙΡΟΝΟΜΙΩΝ ΚΑΙ ΤΗΝ ΚΟΙΝΩΝΙΚΗ ΑΠΟΔΟΧΗ ΚΑΙ ΤΗ ΧΡΗΣΙΜΟΤΗΤΑ ΣΕ ΕΦΑΡΜΟΓΕΣ


%Από εργασία μου δερματά

H αναγνώριση χειρονομιών είναι η διαδικασία κατά την οποία οι χειρονομίες οι οποίες γίνονται από τον χρήστη αναγνωρίζονται από έναν δέκτη. Η αναγνώριση και η ερμηνεία των χειρονομιών απαιτεί από τη μηχανή την ικανότητα να μετρήσει τις δυναμικές ή στατικές παραμορφώσεις του χεριού, του βραχίονα ή ακόμα και άλλων μερών του ανθρωπίνου σώματος, τα οποία συμμετέχουν στην κίνηση.

Σε κάθε σύστημα αναγνώρισης χειρονομιών το πρώτο στάδιο είναι η συλλογή δεδομένων από τον χρήστη.Οι πρώτες συσκευές συλλογής δεδομένων βασιζόντουσαν στη χρήση data gloves και καλωδίων, πράγμα που εμπόδιζε την φυσικότητα στην αλληλεπίδραση του χρήστη.Οι σημερινές προσεγγίσεις αξιοποιούν την χρήση βιντεοκάμερων και τεχνικών υπολογιστικής όρασης που καταγράφουν το αντικείμενο και με τεχνικές αναγνώρισης αναλύουν και ερμηνεύουν τις χειρονομίες.

Πολλές και ποικίλες είναι οι προσεγγίσεις των ερευνητών στην αναγνώριση των χειρονομιών.Αυτά που διαφέρουν σε κάθε προσέγγιση είναι ο τρόπος με τον οποίο κάθε ερευνητής κατάφερε να συλλέξει δεδομένα και οι τεχνικές επεξεργασίας εικόνας που εφάρμοσε για να εξάγει χαρακτηριστικά.

Οι νοηματικές χειρονομίες μπορούν να είναι πολύ σύνθετες, περιέχοντας ταυτόχρονες κινήσεις διάφορων σημείων, ωστόσο πρέπει να περιγραφούν στον υπολογιστή με τρόπο απλό και σαφή.

Pinch It is defined as the movement of expansion and contraction of a nger spread. It has been used for different purposes depending on target applications, e.g. the zooming metaphor by contracting and expanding, scaling or picking. It resembles a grabbing or picking action and offers natural signal to select or move an object in an interactive system and due to the nature of the thumb and index ngers, the pinch grabbing is precise and has high performance.


Human interaction with computer technology has for many years been a machine-centric form of communication. It has relied on the user’s ability to conform to interface strategies that better suit the technology than the user. As the use of computer technology spreads, the physical and expressive limitations of current interaction methods are increasingly counter-productive. Current interface technology such as the mouse and keyboard associated with desktop computers has become ubiquitous in mainstream computing. This role is based on application interface technology that has been used for decades. As the application domain expands, this technology will reveal its performance inhibitions. In an effort to overcome the barrier associated with current interface solutions, much research is being done in the domain of gesture recognition. Because gesture recognition is a natural form of human expression, it seems reasonable to apply it to the communication channel of Human-Computer Interaction (HCI). Several techniques for capturing gesture have been proposed [OKA02, ULHA01, CROW95]. Gesture interpretation for HCI requires the measurability of hand, arm and body configurations. Initial methods were attempted to directly measure hand movements using glove-based strategies. These methods required that the user be attached to the computer through the connecting cables. This restricts the user significantly in their environment.

Overcoming this contact-based interpretation requires the inference-based methods of computer vision. As processor power continues to rise, the once complex algorithms of the field are becoming available as real-time applications. Most computer vision-based gesture recognition strategies focus on static hand gestures known as postures. However, it has been argued that the motion within gesture communication conveys as much meaning as the postures themselves. Examples include global hand motion and isolated fingertip motion analysis. The interpretation of gesture can be broken down into three phases: modeling, analysis and recognition. Gesture modeling involves the schematic description of a gesture system that accounts for its known or inferred properties. Gesture analysis involves the computation of the model parameters based on detected image features captured by the camera. The recognition phase involves the classification of gestures based on the computed model parameters. These phases are outlined in figure 2.12.

Although much research has been done in the field of gesture recognition, HCI interaction involving accurate, real-time interpretation is a long way off. The key to simplifying the domain of human gesture possibilities is to construct a gesture model which clearly describes the sub-domain of gesture that will be classified by the associated system.



To determine an appropriate model for a given HCI system, the application must be clearly defined. Simple gesture requirements result in simple gesture models. Likewise, complex gesture interpretation, involves defining a complex model.

Gesture is defined as the use of body and motion as a form of expression and social interaction. This interaction must be interpreted for communication to be successful. Gesture interpretation is considered a psychological issue, which plays a role in the taxonomy of the varying types of human gesture. Figure 2.13 outlines one such taxonomy.

It is crucial for any gesture recognition system to distinguish between the higher level classifications such as gesture versus unintentional movements and manipulation versus communicative. It has been suggested that the temporal domain of human gesture, for example, can help classify a gesture from unintentional movement. The temporal aspect of gesture has three phases: preparation, nucleus, and retraction [PAVL97]. The preparation phase involves the preparatory movement of the body from its rest position. The nucleus phase involves a definite form of body, while the retraction phase describes the return of the body to its rest position. The preparation and retraction phase are characterized by rapid motion, whereas the nucleus phase shows relatively slow motion. Some measurable stray from these temporal properties could indicate unintentional movement as opposed to gestures in the classification process. Two forms of modeling are being explored; appearance and 3D model-based modeling. Appearance-based modeling deals with the direct interpretation of gesture from images using templates. Image content features such as contours, edges, moments and even fingertips can form a basis for parameter extraction with respect to the gesture model chosen. Three-dimensional model-based modeling is used to describe motion and posture in order to then infer the gesture information. Volumetric models are visually descriptive, but are complex to interpret using computer vision. Skeletal models describe joint angles which can be used to infer posture and track motion.


\subsection{Αναγνώριση Blob}
%ΤΙ ΕΙΝΑΙ Η ΑΝΑΓΝΩΡΙΣΗ BLOB


\subsection{Αναγνώριση Χειρονομίας Τσιμπήματος}
%ANALYΣΕ ΤΟ PINCH, ΠΩΣ ΓΙΝΕΤΑΙ, ΓΙΑΤΙ ΕΙΝΑΙ ΕΥΚΟΛΟ,ΠΟΥ ΧΡΗΣΙΜΟΠΟΙΕΙΤΑΙ, ΠΩΣ ΑΝΙΧΝΕΥΕΤΑΙ(WILSON,ETC)

%wang-popovi


Pinching has been shown to be an effective gesture for “clicking”
in 3D space. Hilliges and colleagues use a single depth
camera to detect pinches above a table top [9]. Benko and
Wilson [4] track pinches using an infrared camera above a
projector. Wilson uses a webcam to detect pinches above
the keyboard [26]. However, all three approaches rely on
a single-view pinch detection technique that suffers from occlusions,
restricting the hand orientations that can be tracked.
A unique feature of our approach is the use of two widebaseline
viewpoints. Our two-view approach resolves occlusions
from one view using information from the other, enabling
robust gesture (e.g. pinch) detection. Our contribution
is independent of the particular type of camera used (depth
or RGB).
%--

Successful gesture recognition requires clear classification of the model parameters. This process can be difficult when attempting feature extraction schemes that rely on complex computer vision techniques. For example, contours can be misinterpreted when used for the recognition of gesture so their use is usually restricted to tracking. On the other hand, slight changes in hand rotation while presenting the same posture can be interpreted as different postures using geometric moments. Temporal variance is an important issue that needs to be studied in more detail. For example, hand clapping should be recognized properly regardless if it is done slowly or quickly. Hidden Markov Models (HMMs) have shown promise in distinguishing gesture in the presence of duration and variation changes

Another recognition approach is to use motion history images (MHIs) or temporal templates. Motion templates accumulate the motion history of a sequence of visual images into a single two-dimensional image. Each MHI is parameterized by the time history window that was used for its computation. Multiple templates with varying history window times are gathered to allow time duration invariance. This process is computationally simple, but recognition problems can stem from the presence of artifacts in the images when auxiliary motions are present. Although it seems that 3D model-based approaches can capture the richest set of hand gestures in HCI, the applications that use such methods are rarely real-time. The most widely used gesture recognition approaches use appearance-based models. Current applications in the field of hand gesture related to HCI are attempting to replace the keyboard and mouse hardware with gesture recognition. Exciting possibilities with helping physically-challenged individuals and the manipulation of virtual objects are being explored.



%\section{Διαδραστική Επαυξημένη Πραγματικότητα}
%OTI ΔΕΝ ΕΙΠΑΜΕ ΣΤΗΝ ΕΙΣΑΓΩΓΗ ΓΙΑ AR, ΚΥΡΙΩΣ ΑΝΑΦΟΡΑ ΕΡΓΑΣΙΩΝ ΠΟΥ ΑΣΧΟΛΟΥΝΤΑΙ ΜΕ INTERACTION OF VIRTUAL OBJECTS, KAI MEΘΟΔΟΥΣ ΠΟΥ ΧΡΗΣΙΜΟΠΟΙΟΥΝΤΑΙ, ΓΙΑΤΙ ΕΙΝΑΙ ΧΡΗΣΙΜΗ Η ΑΛΛΗΛΕΠΙΔΡΑΣΗ ΣΤΟ ar


\section{Σχετικές Ερευνητικές Εργασίες}
%ΑΝΑΦΕΡΕ ΠΑΡΟΜΟΙΕΣ ΕΡΓΑΣΙΕΣ ΓΙΑ GESTURE INTERACTION, AR TABLETOP GAMING, KAI AZUMA CLASSICS ETC.
%ΠΕΣ ΣΙΓΟΥΡΑ ΓΙΑ ΠΑΡΟΜΟΙΑ ΣΚΑΚΙΑ ΣΤΟ ΤΕΛΟΣ
%ΨΑΧΝΟΝΤΑΣ ΣΕ PAPERS ΑΝΑΦΕΡΕ ΠΑΡΟΜΟΙΕΣ ΕΡΓΑΣΙΕΣ ΝΑ ΕΧΟΥΝ ΣΧΕΣΗ ΜΕ GESTURE RECOGNITION FOR AR, VIRTUAL OBJECT MANIPULATION, AR TABLETOP GAMES
Σε προηγούμενες ερευνητικές εργασίες, παρουσιάστηκαν διαφορετικές προσεγγίσεις για την κατανόηση των δυνατοτήτων που προσφέρουν οι χειρονομίες στην αλληλεπίδραση με εικονικά αντικείμενα σε ένα περιβάλλον επαυξημένης πραγματικότητας. Επιπλέον, σε βιβλιογραφικές αναφορές μπορούμε να εντοπίσουμε τις δυνατότητες της επαυξημένης πραγματικότητας στον χώρο της ψυχαγωγίας και συγκεκριμένα των βιντεοπαιχνιδιών, τις βασικές έννοιες της αλληλεπίδρασης μεσω χειρονομιών και της ρεαλιστικής απεικόνισης εικονικών αντικειμένων.


%thomas-cie-apps of ar gaming
Augmented reality chess games have been implemented on previous works. One approach
[1] used a handheld pen prop with a marker cube on top of it in order to interact with the
chess pieces. As the writers admit, the tracking of interaction props was inaccurate and slow
to provide unencumbered and natural use. Another one[2] used nger tracking techniques that
allow gestural interaction with the chess pieces. In this approach, manipulation of virtual objects
is possible using grab and release gestures, as well as image processing techniques to detect hand
gestures, using a single camera. The nger tracker that is implemented is using a hands 3D
model that can determine enough information to robustly track the position, orientation and
pose of the users index nger. However, this solution resorts to using a marked glove with
retro-re
ective spheres on top of the forengers joints, something that may disturb users and is
denitely not a natural way to interact with content. Other approaches utilize mobile markers
that correspond to a specic type of chess piece and users had to move the markers to different
positions of a chessboard in order to play the chess game. Of course this would take quite an
amount of effort to correctly print and create the congurable chessboard and is really similar
to just using a real chessboard with real chess pieces.


Η εφαρμογή AR2Hockey ήταν ένα από τα πρώτα βιντεοπαιχνίδια στο χώρο της επαυξημένης πραγματικότητας[Ohshima et al. 1998]. Στο συγκεκριμένο παιχνίδια, χρησιμοποιοιείται τεχνολογία optical see-through HMD display για 2 παίκτες. The game is played on a standard table with landmarks. The landmarks allow for a hybrid optical tracking and the Polhemus’ Fastrack. The game basically supports the traditional form of air hockey, but replaces the physical pucks with virtual ones. As an extension to this,Mueller et al. developed an AR remote version of air hockey [Mueller et al. 2006]. Two remote physical air hockey tables, one for each player, provide the playing surface for the game. There is a video conferencing display across the middle of each table providing a real-time video feed of the other player. What makes this game different is that the users play with physical pucks. Once a puck is hit across the table, it is caught with a mechanism under the video conference display. The mechanism then automatically shoots the puck back in response to the shot from the other player. The game of pool (or billiards) has been investigated by a number of researchers as an application domain for AR. Jebara et al. developed the first mobile AR pool system [Jebara et al. 1997]. This is an HMDbased AR game, for which many of the first algorithms for image processing and physics engines for pool-based games were developed. This game served as a trainer for the end user by displaying AR information on the correct cue placement. Each of these games supports a physical gaming interface, adding to the evidence that AR incorporates both the physical and virtual worlds. AR2Hockey was a very early AR game, and as such required more expensive display and tracking equipment; but the price for both these forms of hardware has fallen dramatically. The Jebara et al. pool system also required a large structure, the pool table, to play the game upon. This system also incorporates a tutoring system for the players, including suggestions for shots.


A number of AR card games have been developed: Billinghurst et al. created an ARToolkit memory game, where the users flip physical cards [Billinghurst et al. 2000]. When a card is flipped over, a 3D graphic is displayed. The cards interact with each other by playing an animation when there is a match between the cards. This was the first AR game developed with the ARToolkit. Diaz et al. created a variant which employed hand gestures as the means of interaction [Diaz et al. 2006]. They used special cards to enable the system to sense card flipping by embedding Hall effect switches in the cards. BattleBoard is another example of a tabletop AR card game [Andersen et al. 2004]. This is an ARToolkit fiducial marker-based AR system which attaches virtual game pieces to the markers. One player employs an HMD with a camera and the second player views the game through a monitor. Battles are fought when pieces come in close proximity to each other, and thus activate AR animations. The Billinghurst et al. card game was designed for a public demonstration at an ACM SIGGraph conference with quick gameplay. BattleBoard employs a similar technology to the Billinghurst et al. card game, but BattleBoard’s design is more advanced, and is similar to a duelling card game. The Tankwar game was developed for more extended gameplay, investigating how AR could be employed for games with a more traditional time span.


%interaction in ar games
A drama-based game, Fac¸ade, was extended into an HMD AR version, AR Fac¸ade [Dow et al. 2007a, 2006, 2007b]. This game is a major break from traditional AR gaming ideas developed previously. This is a complex, real-life, role-playing game; very much like interactive theatre. Originally, the game was played on a traditional workstation; AR Fac¸ade is played on a HMD with a mobile backpack system, with gestures and voice as the main forms of interaction. The authors constructed virtual and physical representations of many of the game objects, such as walls and furniture, in an apartment. Objects that were manipulated by both the virtual characters and the physical players were presented as AR objects to the game player in the HMD. Due to the large area the game is played in a large area with an IS1200 tracking system. A Wizard of Oz method was employed to support user interactions to make formore robust gesture and speech processing systems during user studies. The authors found this form of interaction engaging for the user, but more research is required

%playstation app with board and monitor for AR
Το βιντεοπαιχνίδι Eye of Judgement της πλατφόρμας Sony PS3 είναι ένα βιντεοπαιχνίδι επαυξημένης πραγματικότητας σε τρίτο πρόσωπο, που περιλαμβάνει μία ψηφιακή βιντεοκάμερα η οποία καταγράφει το ταμπλό του παιχνιδιού και απεικονίζει μία επαυξημένη του έκδοση στην τηλεόραση. Αυτός ο τύπος παιχνιδιού απαιτεί από τους χρήστες να επικεντρώνουν την προσοχή τους τόσο στο πραγματικό ταμπλό, όσο και στην έκδοση που παρουσιάζεται στην οθόνη. Μόλις οι κάρτες του παιχνιδιού τοποθετηθούν πάνω στο ταμπλό, δρουν ως καθοδηγητικοί δείκτες(markers) για τον εντοπισμό τεράτων επαυξημένης πραγματικότητας και τα κομμάτια του παιχνιδιού απεικονίζονται επάνω τους. Η μηχανή παιχνιδιών αναλαμβάνει τα τρισδιάστατα γραφικά των καρτών μόλις εντοπιστούν. Το παιχνιδί αυτό, ήταν ένα από τα πρώτα εμπορικά βιντεοπαιχνίδια επαυξημένης πραγματικότητας που κυκλοφόρησαν στην αγορά που επέτρεπε τη χρήση καθογητητικών δεικτών (fiducial markers).


%Εργασίες με σκάκι ή pinch gestures για χειρισμό εικονικών αντικειμένων 
Οι Dorfmuller-Ulhaas και Schmalstieg δημιούργησαν ένα σύστημα οπτικής ανίχνευσης δακτύλων, με απώτερο σκοπό την αφαίρεση των ενοχλητικών καλωδίων κατά τη διάρκεια της αλληλεπίδρασης με τα εικονικά αντικείμενα. Μάλιστα, η τεχνολογίας που ανέπτυξαν, παρουσιάστηκε μέσα από μία επαυξημένη έκδοση ενός πολύ γνωστού παιχνιδιού, που δεν είναι άλλο από το σκάκι. [Dorfmuller-Ulhaas and Schmalstieg 2001].

%vale kai mobile collaborative ar chess


%wang,popovi
RELATED WORK
Many methods have been proposed for markerless or gloveless
hand tracking, but they are either too slow for interactive
applications, e.g. [24, 7], or the range of poses that they can
detect do not permit the precise selection required in CAD
applications, e.g. [14, 13, 20]. In comparison, our system
achieves bimanual 6-DOF pose estimation at interactive rates
and reliably detects poses suited for discrete selection such as
pinching and pointing.
Glove tracking has been proposed to ease and speed up the
problem of hand tracking, e.g. [27, 25]. However, gloves are
a significant drawback if one wants to also use the keyboard
and mouse. Users may be reluctant to put on a glove when
switching from a 2D task such as menu navigation to a 3D
task such as object assembly. Wearing a glove may also become
uncomfortable during long work sessions.


%krevelen
Besides registering virtual data with the user‟s real world
perception, the system needs to provide some kind of interface
with both virtual and real objects. Our technological
advancing society needs new ways of interfacing with both
the physical and digital world to enable people to engage in
those environments [67]. 
WIMP (windows, icons, menus, and pointing), as the
conventional desktop UI metaphor is referred to, does not
apply that well to AR systems. Not only is interaction required
with six degrees of freedom (6DOF) rather than 2D, the use of conventional devices like a mouse and keyboard
are cumbersome to wear and reduce the AR experience.
Like in WIMP UIs, AR interfaces have to support selecting,
positioning, and rotating of virtual objects, drawing
paths or trajectories, assigning quantitative values (quantification)
and text input. However as a general UI principle,
AR interaction also includes the selection, annotation, and,
possibly, direct manipulation of physical objects. This
computing paradigm is still a challenge [20].




In stead of using hand-worn trackers, hand movement may
also be tracked visually, leaving the hands unencumbered. A
head-worn or collar-mounted camera pointed at the user‟s
hands can be used for gesture recognition. Through gesture
recognition, an AR could automatically draw up reports of
activities [105]. For 3D interaction, UbiHand uses
wrist-mounted cameras enable gesture recognition [14],
while the Mobile Augmented Reality Interface Sign Interpretation Language 16 [16] recognises hand gestures on a
virtual keyboard displayed on the user‟s hand (Fig. 12). A
simple hand gesture using the Handy AR system can also be
used for the initialization of markerless tracking, which estimates
a camera pose from a user‟s outstretched hand [97].
Cameras are also useful to record and document the user‟s
view, e.g. for providing a live video feed for teleconferencing,
for informing a remote expert about the findings of AR
field-workers, or simply for documenting and storing everything
that is taking place in front of the mobile AR system
user.
Common in indoor virtual or augmented environments is
the use of additional orientation and position trackers to
provide 6DOF hand tracking for manipulating virtual objects.
For outdoor environments, Foxlin and Harrington [60] experimented
with ultrasonic tracking of finger-worn acoustic
emitters using three head-worn microphones




Immersed in an environment containing virtual information, the user is left with few mechanisms for interacting with the virtual augmentations. The use of hardware devices [VEIG02] can be physically restrictive given the special freedom goals of Augmented Reality. Interaction with virtual augmentation through a physical mediator such as a touch screen [ULHA01] is becoming a common practice. An interesting alternative is the use of natural human gestures to communicate directly with the environment. Gesture recognition has been explored mainly for the purpose of communicative interaction. Gesture systems have explored many aspects of hand gesture including three-dimensional hand posture [HEAP96] and fingertip motion [OKA02, ULHA01, CROW95]. The system presented in this chapter attempts to bridge these two fields of study by describing a hand gesture system that is used for manipulative interaction with the virtual augmentation. Although natural human gestures are too complex to recognize in realtime, simple gesture models can be defined to allow a practical interactive medium for real-time Augmented Reality systems.

\section{Προκλήσεις και προβλήματα}
%ΣΥΓΧΡΟΝΑ ΠΡΟΒΛΗΜΑΤΑ ΣΤΟ AR

Μία από τις μεγαλύτερες προκλήσεις με τις οποίες έρχονται αντιμέτωποι οι δημιουργοί εφαρμογών επαυξημένης πραγματικότητας είναι η σωστή τοποθέτηση του εικονικού αντικειμένου εντός του πραγματικού περιβάλλοντος, έτσι ώστε η συνθετική πληροφορία να δίνει την εντύπωση ότι ανήκει σε αυτό. Η διαδικασία αυτή είναι γνωστή ως registration (γεωαναφορά). Η σωστή συγχώνευση και ευθυγράμμιση των δύο κόσμων – του φυσικού και του παραγόμενου από υπολογιστή – είναι κύρια προϋπόθεση για την εκπλήρωση του στόχου των εφαρμογών επαυξημένης πραγματικότητας, ενώ λάθη ή ανακρίβειες στην τοποθέτηση του εικονικού αντικειμένου θα έχουν ως αποτέλεσμα να χαθεί η ψευδαίσθηση ότι οι δύο κόσμοι συνυπάρχουν [3]. Πολλές εφαρμογές, μάλιστα, όπως για παράδειγμα στην ιατρική, απαιτούν ακριβή γεωαναφορά και δεν είναι επιτρεπτά λάθη και αστοχίες. Για τη σωστή γεωαναφορά, απαραίτητη προϋπόθεση είναι η πρότερη ανίχνευση της θέσης και του προσανατολισμού της κάμερας – και γενικά της συσκευής μέσω της οποίας επαυξάνεται η πραγματικότητα – ή του κεφαλιού του χρήστη (π.χ. σε εφαρμογή με HMD). Η διαδικασία αυτή είναι γνωστή ως tracking (ανίχνευση), απαντά στα ερωτήματα: πού βρίσκεται ο χρήστης, πού εστιάζεται το ενδιαφέρον του και πού πρέπει να παρουσιαστεί το εικονικό αντικείμενο [72] και συνεπώς η σωστή και ακριβής, ανάλογα με την εφαρμογή διεκπεραίωσή της είναι κρίσιμη για τη δημιουργία πειστικών εφαρμογών επαυξημένης πραγματικότητας. Για την επίτευξη των τελευταίων, η ανίχνευση πρέπει πρακτικά να διεξάγεται σε πραγματικό χρόνο, δηλαδή η εκτίμηση της θέσης να γίνεται σε χιλιοστά του δευτερολέπτου, καθώς επίσης και να είναι εύρωστη, δηλαδή να δίνει ικανοποιητικά αποτελέσματα κάτω από ποικίλες συνθήκες, όπως για παράδειγμα σε μεταβαλλόμενο φωτισμό [68]. Υπάρχουν πολλές μέθοδοι ανίχνευσης 6 βαθμών ελευθερίας (6DOF tracking), όπως το μηχανικό tracking, τεχνική που υιοθετήθηκε και από το πρώτο σύστημα επαυξημένης πραγματικότητας του Sutherland, το υπερηχητικό tracking και το οπτικό tracking. Υπάρχουν και άλλες που υπολογίζουν μόνο θέση ή προσανατολισμό, όπως για παράδειγμα το tracking που βασίζεται σε πληροφορίες μόνο από GPS ή μόνο από γυροσκόπια [15]. Για εφαρμογές που απαιτούν ακριβή γεωαναφορά, ωστόσο, απαιτείται ακριβές στιγμιαίο 6DOF tracking υπό οποιεσδήποτε συνθήκες. Επειδή η τέλεια ανίχνευση είναι – τουλάχιστον προς το παρόν – ανέφικτη, εξαιτίας των χρονικών καθυστερήσεων ή και των περιορισμών λόγω ακριβείας, κύρια πρόκληση αποτελεί η εύρεση της μεθόδου ανίχνευσης που είναι ιδανική για τη συγκεκριμένη κάθε φορά εφαρμογή [73]. Υπάρχει ένας ακόμη αριθμός προκλήσεων που συνδέονται με το πρόβλημα της ανίχνευσης και τοποθέτησης του εικονικού αντικειμένου εντός του φυσικού περιβάλλοντος [4], η κυριότερη από τις οποίες είναι οι αποκρύψεις (occlusion). Σύμφωνα με την τελευταία, πρέπει να επιτυγχάνεται η πλήρης ή μερική απόκρυψη του εικονικού αντικειμένου όταν κάποιο άλλο αντικείμενο του πραγματικού περιβάλλοντος τοποθετείται μπροστά από αυτό και το κρύβει, πλήρως ή μερικώς. Άλλη δυσκολία στις εφαρμογές επαυξημένης πραγματικότητας, σχετική με την οπτική ανίχνευση, είναι η μη εστιασμένη κάμερα στο marker ή στο πρότυπο που πρέπει να αναγνωριστεί για την επαύξηση της πραγματικότητας, γεγονός το οποίο μπορεί να οδηγήσει στη μη αναγνώρισή του, ή σε λάθη στην τοποθέτηση του εικονικού αντικειμένου, λόγω της χαμηλότερης ακρίβειας με την οποία αποδίδεται. Μία ακόμη πρόκληση, συγγενική με την οπτική ανίχνευση (visual tracking), είναι ο μη ομοιόμορφος φωτισμός, λόγω του οποίου ένα marker μπορεί να συσκοτιστεί σε κάποια τμήματά του και να μην αναγνωρίζεται από το πρόγραμμα ή να αναγνωρίζεται ως διαφορετικό marker. Όμοια, λόγω μεταβαλλόμενου φωτισμού, υπάρχει η πιθανότητα μη αναγνώρισης της εικόνας που έχει οριστεί ως πρότυπο. Τέλος, η θαμπάδα που μπορεί να προκληθεί λόγω γρήγορης κίνησης της κάμερας – κυρίως μίας κινητής συσκευής – είναι ένας ακόμα παράγοντας που δύναται να δυσκολέψει τη σωστή επαύξηση της πραγματικής σκηνής. Ένα κύριο στοιχείο των εφαρμογών επαυξημένης πραγματικότητας είναι η απεικόνιση του εικονικού αντικειμένου στην πραγματική σκηνή, δηλαδή η δημιουργία της συνθετικής επαυξημένης σκηνής, σε πραγματικό χρόνο (real-time rendering). Η φύση κάποιων εφαρμογών απαιτεί οι γραφικές πληροφορίες να ενσωματώνονται στο φυσικό περιβάλλον με τέτοιο τρόπο ώστε ο παρατηρητής να μην μπορεί να ξεχωρίσει ποιο είναι το πραγματικό και ποιο το εικονικό. Στις εφαρμογές αυτές, εκτός από το σωστό και ακριβές tracking και registration, απαιτείται ταυτόχρονα και φωτορεαλιστικό rendering, με σωστή σκίαση και φωτισμό του εικονικού αντικειμένου και οποιαδήποτε άλλη αυτόματη από το λογισμικό επεξεργασία πραγματικού χρόνου αυτό συνεπάγεται [6]. Καθοριστικό στοιχείο στη βελτίωση της ποιότητας του rendering αποτελεί η ικανότητα της εφαρμογής να λαμβάνει και να αξιοποιεί πληροφορία για το φωτισμό του περιβάλλοντος και την ανάκλαση [3]. Ένα ακόμη βασικό στοιχείο των εφαρμογών επαυξημένης πραγματικότητας είναι, όπως έχει ήδη αναφερθεί, η τεχνολογία θέασης, η οποία ταυτόχρονα αποτελεί και μία πρόκληση, καθώς η βελτίωσή της, ανάλογα με τις απαιτήσεις της εκάστοτε εφαρμογής, μπορεί να συντελέσει σε μεγαλύτερη αποδοχή της τεχνολογίας αυτής από το κοινό. Πράγματι, είναι πολύ πιο βολικό και «γνώριμο» στον άνθρωπο να φορέσει γυαλιά ή φακούς που θα επαυξήσουν την πραγματικότητά του σε σχέση με κάποια βαριά και μεγάλη συσκευή που προσαρτάται στο κεφάλι του (HMD ή HMPD). Εκτός από τέτοιου είδους περιορισμούς, που οφείλονται στον ανθρώπινο παράγοντα και για τους οποίους γίνονται σήμερα πολλές προσπάθειες βελτίωσης, υφίστανται και άλλες προκλήσεις σχετικές με την τεχνολογία θέασης της επαυξημένης πραγματικότητας [6], όπως είναι για παράδειγμα οι οπτικοί περιορισμοί λόγω του περιορισμένου οπτικού πεδίου του χρήστη, καθώς και οι τεχνικοί περιορισμοί, όπως η περιορισμένη ανάλυση και διάφοροι άλλοι παράγοντες. Εκτός των παραπάνω σημαντικών προκλήσεων με τις οποίες έρχονται αντιμέτωπες οι εφαρμογές επαυξημένης πραγματικότητας, υπάρχουν και άλλα τεχνικά ζητήματα σχετικά με αυτές, όπως είναι η αλληλεπίδραση του χρήστη με την εικονική πληροφορία, γεγονός το οποίο θα του δώσει την αίσθηση της πλήρους ενσωμάτωσης στο συνθετικό αυτό κόσμο, που συνδυάζει το πραγματικό με το εικονικό. Τέλος, οι δημιουργοί των εφαρμογών επαυξημένης πραγματικότητας πρέπει να δίνουν σημασία και στο πλήθος των εικονικών πληροφοριών που υπερτίθενται στο πραγματικό περιβάλλον του χρήστη, έτσι ώστε αυτό να μην εμποδίζει το χρήστη από τη θέαση του φυσικού κόσμου, αλλά ούτε και να είναι ανεπαρκές.
 
%krevelen

AR faces technical challenges regarding for example binocular
(stereo) view, high resolution, colour depth, luminance,
contrast, field of view, and focus depth. However,
before AR becomes accepted as part of user‟s everyday life,
just like mobile phones and personal digital assistants
(PDAs), issues regarding intuitive interfaces, costs, weight,
power usage, ergonomics, and appearance must also be addressed.
A number of limitations, some of which have been
mentioned earlier, are categorised here.

-Portability and outdoor use
Most mobile AR systems mentioned in this survey are
cumbersome, requiring a heavy backpack to carry the PC,
sensors, display, batteries, and everything else. Connections
between all the devices must be able to withstand outdoor use,
including weather and shock, but universal serial bus (USB)
connectors are known to fail easily. However, recent developments
in mobile technology like cell phones and PDAs
are bridging the gap towards mobile AR.
Optical and video see-through displays are usually unsuited
for outdoor use due to low brightness, contrast, resolution,
and field of view. However, recently developed at
MicroVision, laser-powered displays offer a new dimension
in head-mounted and hand-held displays that overcomes this
problem.
Most portable computers have only one CPU which limits
the amount of visual and hybrid tracking. More generally,
consumer operating systems are not suited for real-time
computing, while specialised real-time operating systems
don‟t have the drivers to support the sensors and graphics in
modern hardware.

-Tracking and (auto)calibration
Tracking in unprepared environments remains a challenge
but hybrid approaches are becoming small enough to be added to mobile phones or PDAs. Calibration of these devices
is still complicated and extensive, but this may be
solved through calibration-free or auto-calibrating approaches
that minimise set-up requirements. The latter use
redundant sensor information to automatically measure and
compensate for changing calibration parameters [19].
Latency A large source of dynamic registration errors are
system delays [19]. Techniques like precalculation, temporal
stream matching (in video see-through such as live broadcasts),
and prediction of future viewpoints may solve some
delay. System latency can also be scheduled to reduce errors
through careful system design, and pre-rendered images may
be shifted at the last instant to compensate for pan-tilt motions.
Similarly, image warping may correct delays in 6DOF
motion (both translation and rotation).

-Depth perception
One difficult registration problem is accurate depth perception.
Stereoscopic displays help, but additional problems
including accommodation-vergence conflicts or low resolution
and dim displays cause object to appear further away
than they should be [52]. Correct occlusion ameliorates some
depth problems [138], as does consistent registration for
different eyepoint locations [158].
In early video see-through systems with a parallax, users
need to adapt to vertical displaced viewpoints. In an experiment
by Biocca and Rolland [35], subjects exhibit a large
overshoot in a depth-pointing task after removing the HMD.

-Overload and over-reliance
Aside from technical challenges, the user interface must
also follow some guidelines as not to overload the user with
information while also preventing the user to overly rely on
the AR system such that important cues from the environment
are missed [156]. At BMW, Bengler and Passaro [29] use
guidelines for AR system design in cars, including orientation
on the driving task, no moving or obstructing imagery,
add only information that improves driving performance,
avoid side effects like tunnel vision and cognitive capture,
and only use information that does not distract, intrude or
disturb given different situations.

-Social acceptance
Getting people to use AR may be more challenging than
expected, and many factors play a role in social acceptance of
AR ranging from unobtrusive fashionable appearance
(gloves, helmets, etc.) to privacy concerns. For instance,
Accenture‟s Assistant (Fig. 14) blinks a light when it records
for the sole purpose of alerting the person who is being recorded.
These fundamental issues must be addressed before
AR is widely accepted [73].

%---
The diversity of AR platforms, devices, tools and applications is stunning. Overall,
augmented reality is a pronounced visualisation method, which is used in many
application areas. It is especially advantageous in on-site real-time visualisations
of database information and for purposes where there is a need to enhance the
3D perceptive skills of the user. Augmented reality enables natural interactions
and is a good tool to create interactive games and enhance user experience in
other areas as well. In this work, we aim to give a thorough overview of the whole
field, whilst concentrating on the fundamental issues of single-camera visual augmented
reality.


In conclusion, the augmented reality application developer needs to take into consideration several different issues: technical, application and other issues affecting the user experience. The main technological issues relate directly to the definition of augmented reality (real-time, interactive, 3D, combining real and virtual). Application issues arise from the ease of creating AR applications. Other important issues relate to user experience. The main technological issues in augmented reality are 􀁸 performance 􀁸 interaction 􀁸 alignment.

The main application issues are 􀁸 content creation 􀁸 authoring. Other important issues affecting the user experience are 􀁸 visual perception 􀁸 user interface 􀁸 devices 􀁸 power consumption. Next, we review what we mean by these issues and how they affect the usability and user experience of an AR application. An augmented reality system needs to be able to perform in real-time. Otherwise, the system may augment old or flawed information, or the augmentation may not correspond to the current state of the environment. Performance issues are characteristic to all AR algorithm and application development. Research results from other fields (e.g. image processing) are not directly applicable to AR. For instance, traditional image inpainting methods do not fulfil the real-time requirement, and therefore they cannot be used for diminished reality as such (see Section 6.2). Performance is an issue especially in mobile environment where the processing power and memory are limited. The user should be able to interact with the system naturally. The usability and the user experience are disturbed if the interaction is unnatural. The interaction needs to be natural in the user interface level as we discussed in the Section 7.1. The same holds true at the application level; the interaction between the real world objects and virtual objects needs to be smooth as well. Application needs to adapt virtual elements according to real scene, as for example in our interior design application where the user was able to adjust virtual lights easily according to real ones (see Section 6.1.3). At times, the application needs to remove existing objects virtually to be able to augment virtual objects on the same place. We discussed in Section 6.2 how to handle this kind of interaction with diminished reality. The camera calibration needs to be correct and the tracking needs to be accurate. Otherwise, the augmented data is shifted in the real environment: the virtual overlay is in the wrong place or it flutters. People find this alignment error annoying. In Chapter 3, we concentrated on marker-based approaches for accurate tracking, and in Chapter 4, on alternative tracking methods, mainly feature-based tracking and hybrid tracking methods. In addition, Appendix C gives an overview of camera calibration. The content creation is also an important aspect of application development. An application can visualise information from a database (e.g. in augmented assembly) or provide textual information (e.g. in AR browsers). Sometimes the information in database is in unsuitable format and format conversion is needed. In addition, when no database is available someone needs to create the content. Furthermore, if nice graphics are required, they need to be created to the approboth mobile environments and high quality visualisation. Besides content creation, authoring is a big application issue as we discussed in Section 7.4. Creation of AR applications should be brought to a non-expert nonprogramming level, where users can combine objects, interactions and events at a conceptual level. Visual perception should support the purpose of the application as we discussed in Chapter 6. Some applications require (photo-)realistic rendering, other applications benefit from focus and content -type highlighting of augmented objects. The user should be able to concentrate on the task, and the visual perception should sustain the task, without distracting the user. The user interface should be, as always, easy to use and intuitive. It should support the task at hand and make the user experience smooth as discussed in Section 7.1. The AR application should run on the appropriate device; mobile applications on lightweight devices, high-end visualisations on larger good-quality monitors. Furthermore, the terminal device should be taken into account already at the application design stage. There is no point in implementing computationally intensive methods on mobile phones if the application would then run on a slow frame rate. Devices often play very important role in the development process. The diversity of mobile platforms is perhaps the main obstacle for wider use of mobile AR applications. Applications need to be ported mostly to each platform separately, which deprives resources from application development. Furthermore, mobile devices are an ideal platform for consumer applications; they are equipped with cameras and new models with various additional sensors; people carry them with them all the time. Likewise, in special applications where an expert operates the system, it is feasible to invest in special devices such as HMDs, 3D displays, additional sensors, etc. if they support the task. One more aspect that significantly affects user experience is power consumption. Many applications require the user to be able to move freely, and thus wireless devices are optimal and then battery life plays a big role. A mobile application that discharges the battery in 15 minutes is unrealistic. We once tested a HMD where the camera ran out of batteries in less than two hours. The user had to change the batteries often, which was annoying especially as the camera and projector were wired to a computer anyway. It is hard to imagine this kind of setup in practical use, e.g. in a factory. In conclusion, the most important issue of augmented reality application development is the user experience, which is affected by all technological, application and other issues.


